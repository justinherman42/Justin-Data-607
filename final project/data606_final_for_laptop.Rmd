---
title: "R Notebook"
output:
  html_document:
    theme: "simplex"
    highlight: 'pygments'
    toc: true
    toc_float: true
    

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Overview
+ Query my poker postgres database and create customized player statistics
+ Explore these statistics and test to see if assumptions for inference are met
+ Use these statistics to run a multiple linear regression model to try and predict a players winrate

Before I begin, I provide a link [Data 607 Final](https://rpubs.com/justin_herman_42/385739) The link provides a general explanation on why I had to access my postgres database, and also provides a breif explantaion of some of the stats that I will be using.  Copy and pasted from there 

### Explanation of Stats
+ As this is the only poker technical area in this project, I provide a brief explanation of some poker stats. 
+ In texas holdem players are all given two cards and are presented with a betting decision based on only their individual cards. From there they are presented with decisions on what to do as 5 community cards come out over three more rounds of betting.   
+ There are thousands of combinations of hands and hundreds of stats to choose from, but the stats I chose have to do with the first decision every player has to make: 
    + VPIP = How often someone calls their hand `Or` raises/ total hands played
        + Ideal range for this stat is from (22-28)
    + PFR= how often someone raises their hand / /total hands played 
        + Ideal range for this stat is from (16-22)
    + VPIP includes the entire set of PFR 
    + BB/100= how many bets a player wins per 100 hands(how much someone wins)
        + Typically any win rate above 4/bb 100 is considered a solid winning player
        + This stat can be both positive and negative, negative represents losing players
+ Both VPIP and PFR are two of the fastest stats to normalize.  Every hand that someone plays they are faced with a decision that counts toward each of these stats.  Therefore they provide the most immediate information about an opponent and are great proxy's for categorizing players



## Setup Access To Postgres and Load Libraries
```{r,echo=FALSE}
rm(list=ls())
library(XML)
require("RPostgreSQL")
library(tidyverse)
library(kableExtra)
library(knitr)
#library(data.table)
library(psych)
pw <- "password"
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "2017_DB",
                 host = "localhost", port = 5432,
                 user = "postgres", password = pw)

```


### Test connection  

```{r,echo=TRUE}

tryCatch({
    drv <- dbDriver("PostgreSQL")
    print("Connecting to database")
    conn <- con
    print("Connected!")
    },
    error=function(cond) {
            print("Unable to connect to database.")
    })
```

### Explore Postgres DB
```{r}

# query 6 returns player stats but with only sn
# query 7 has id and sn 
query_6 <- dbGetQuery(conn, 'SELECT * FROM players')
query_7 <- dbGetQuery(conn, 'SELECT * FROM compiledplayerresults limit 1000000')
```

### Filter For Pokersite/Columns 
```{r}

## ALl palyers 
all_players <- query_6%>% 
    select(.,c(playername,player_id,cashhands))
player_ids <- all_players$player_id
all_player_stats <- query_7 %>% 
    filter(.,player_id %in% player_ids )
all_players_db<- merge(all_player_stats,all_players,by="player_id" ,all = TRUE)
#write.csv(all_players_db,"allplayers.csv")



## choosen columns 
columns_for_analysis <-c('gametype_id',"player_id","totalhands","totalbbswon","totalrakeincents","totalamountwonincents","vpiphands","pfrhands","couldcoldcall","didcoldcall","couldthreebet","didthreebet","couldsqueeze","didsqueeze","facingtwopreflopraisers","calledtwopreflopraisers","raisedtwopreflopraisers","smallblindstealattempted","smallblindstealdefended","smallblindstealreraised","bigblindstealattempted","bigblindstealdefended","bigblindstealreraised","facedthreebetpreflop","foldedtothreebetpreflop","calledthreebetpreflop","raisedthreebetpreflop","facedfourbetpreflop","foldedtofourbetpreflop","calledfourbetpreflop","raisedfourbetpreflop","sawflop","wonhandwhensawflop","sawshowdown","wonshowdown","flopcontinuationbetpossible","flopcontinuationbetmade","turncontinuationbetpossible","turncontinuationbetmade","rivercontinuationbetpossible","rivercontinuationbetmade","facingflopcontinuationbet","foldedtoflopcontinuationbet","calledflopcontinuationbet","raisedflopcontinuationbet","facingturncontinuationbet","foldedtoturncontinuationbet","calledturncontinuationbet","raisedturncontinuationbet","facingrivercontinuationbet","foldedtorivercontinuationbet","calledrivercontinuationbet","raisedrivercontinuationbet","playername","cashhands")    
              
## create function to round and sum vectors
#vector x, vector y, round integer z
 trans_func <- function(x,y,z){
     round(sum(x)/sum(y)*100,z)
 }
```

### Create final df
+ Filter by desired stats
+ Groupby to aggreegate by player
+ Build desired stats 
```{r}
predictors <- c("vpip", "pfr", "threebet", "bb_per_100", "wwsf")
indexes <- c((1:31),65)
#all_players_db$totalbbswon <- all_players_db$totalbbswon*100
all_players_finished_db <- all_players_db %>%
    filter(.,gametype_id %in% indexes ) %>% 
    select(c(columns_for_analysis)) %>%  
    group_by(playername) %>% 
    summarize(
  vpip= round(sum(vpiphands)/sum(totalhands)*100,1),
  pfr=round(sum(pfrhands)/sum(totalhands)*100,1),
  total_hands    =  sum(totalhands),
  money_won      =  sum(totalamountwonincents),
  rake           =  sum(totalrakeincents),
  threebet       =  round(sum(didthreebet)/sum(couldthreebet)*100,1),
  bb_per_100     =  round(sum(totalbbswon)/(sum(totalhands)),2),
  total_rake_100 =  round((sum(totalrakeincents)/100)/sum(total_hands),2),
  money_won_100  =  round((sum(totalamountwonincents)/100)/(sum(total_hands)/100)/100,2),
  wwsf           = round(sum(wonhandwhensawflop)/sum(sawflop)*100,1))


#all_players_finished_db <- all_players_finished_db %>% 
 #   select(.,c(predictors))

# Print out of my statistics 
all_players_finished_db %>% 
    filter(playername=="RileyFreeman")

```                 


## Data Exploration 

### Determine proper hand count for our observations
+ Some stats can take thousands of hands to normalize
    + I will filter by 4 different hands played filters and see how well the distributions approach normality
```{r,echo=FALSE,message=FALSE}

## Github reproducibility
write.csv(all_players_finished_db,"data606finaldb.csv")
all_players_finished_db <- read.csv('data606finaldb.csv')

library(datapasta)
over_50_hands <- all_players_finished_db %>% 
    filter(.,total_hands>50) %>% 
    select(.,c(predictors))

over_100_hands <- all_players_finished_db %>% 
    filter(.,total_hands>100) %>% 
    select(.,c(predictors))

over_500_hands <- all_players_finished_db %>% 
    filter(.,total_hands>500) %>% 
    select(.,c(predictors))

over_1000_hands <- all_players_finished_db %>% 
    filter(.,total_hands>1000) %>% 
    select(.,c(predictors))
over_2500_hands<- all_players_finished_db %>% 
    filter(.,total_hands>2500) %>% 
    select(.,c(predictors))

predictors <- c("vpip", "pfr", "threebet", "bb_per_100", "wwsf")

## Examoine distributions of predictors over the different databases 
par(mfrow=c(2, 3)) 
mapply(hist,all_players_finished_db[,predictors],main=colnames(over_50_hands),xlab="All hands(no hands filter)")
mtext("Figure 1", SOUTH<-1, line=3, adj=3.0, 
      col="blue")
par(mfrow=c(2, 5)) 
mapply(hist,over_50_hands[,predictors],main=colnames(over_50_hands),xlab="FIGURE 2 = over50 hands")
mapply(hist,over_100_hands[,predictors],main=colnames(over_500_hands[,predictors]),xlab="FIGURE 2 - over100 hands")
par(mfrow=c(2, 5)) 
mapply(hist,over_500_hands[,predictors],main=colnames(over_500_hands[,predictors]),xlab="FIGURE 3 - over500 hands") 
mapply(hist,over_2500_hands[,predictors],main=colnames(over_500_hands[,predictors]),xlab="FIGURE 3 - over2500 hands")



```

## Observations 

### Closser look at db with no filter for hands played 
+ Looking at figure 1, our distributions are all over the place
    + WWSF- seems to have alot of 100 and 0 frequncy scores.  This makes sense as nearly 23k players have played less than 50 hands. Our sample size effectively prevents our data set from displaying as a true continuous variable.  
+ Lets take a closer look at what the under 50 hands played distributions look like below

#### Under 50 Hands
```{r}
under_50_hands <- all_players_finished_db %>% 
    filter(.,total_hands<50)
par(mfrow=c(2, 3)) 
mapply(hist,under_50_hands[,predictors],main=colnames(under_50_hands[,predictors]),xlab=" Under50 hands")
mtext("Figure 3", SOUTH<-1, line=3, adj=3.0, 
      col="blue")
```
   
    
+ 0 becomes our mode in the under 50 hands played for WWSF, 
+ 50 is the 2nd highest value, and 100 is the third highest value.  
+ WWSF describes how often someone wins a hand, given that they saw a flop.  It is very unlikely, given a larger sample size, that a player would win/lose every hand when they saw the flop or play exactly an even amount of hands and win every other one; yet these outcomes make up nearly 39% of our WWSF results in the under 50 hands df. Math below 
  
```{r,}
wwsf_50 <- all_players_finished_db %>% 
    filter(.,total_hands<50) %>% 
    select(wwsf) %>% 
    filter(.,wwsf==50)
wwsf_0 <- all_players_finished_db %>% 
    filter(.,total_hands<50) %>% 
    select(wwsf) %>% 
    filter(.,wwsf==0)
wwsf_100 <- all_players_finished_db %>% 
    filter(.,total_hands<50) %>% 
    select(wwsf) %>% 
    filter(.,wwsf==100)
paste("wwsf of 0 = ",count(wwsf_0),"wwsf of 50 = ",count(wwsf_50)," wwsf of 100 =",count(wwsf_100),"total occurences = 23183" )
kable(paste("these 3 values(0,50,100) make up ", round((4462+2618+1897)/23183,2),"% of total occurences"))

```
  
        
+ Confidence intervals for our WWSF stat would be interesting, but it doesn't fall within the point of my analysis.  I am trying to ballpark when my dataset variables become continuous.  Therefore the logical assumptions above, are enough to show that we have not met a sample size large enough to run our analysis on.  
+ We can apply this same frameowrk to other stats as well, therefore We need to increase our filter by hand requirement to allow for the stats to become continuous. 
+ Although normality of my input variables isn't a requirement, I would like to see if they do become normal as the hand filter increases as well

### Comparing 50 and 100 hand filters with describe
+ The over 50 and over 100 hands Dataframes are displayed together above in figure 2
    + We can already see a much more normalized distribution across the board of our predictor stats
        + WWSF has normalized and we can assume our varibales are continuous 
        + Lets explore deeper, by running a describe function over these two df
```{r,echo=FALSE}
#library(ggpubr)


describe_over_50_hands <- describe(over_50_hands)
#describe_over_50_hands<- describe_over_50_hands %>% 
#    select(.,predictors)

df_describe_50_hands <- as_data_frame(lapply(describe_over_50_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_50_hands) <- colnames(describe_over_50_hands)
 rownames(df_describe_50_hands) <- rownames(describe_over_50_hands)
 kable(df_describe_50_hands,caption = "Figure 4 - Over 50 hands")
 
describe_over_100_hands <- describe(over_100_hands)
describe_over_100_hands<- describe_over_100_hands[predictors,]
df_describe_100_hands <- as_data_frame(lapply(describe_over_100_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_100_hands) <- colnames(describe_over_100_hands)
 rownames(df_describe_100_hands) <- rownames(describe_over_100_hands)
 kable(df_describe_100_hands,caption = "Figure 5 - Over 100")
```
 
     
+ The stats seem to fit each other very well

### Run describe function over the rest of the filtered df's 
 
```{r, echo=FALSE}
 describe_over_500_hands <- describe(over_500_hands)
describe_over_500_hands<- describe_over_500_hands[predictors,]
df_describe_500_hands <- as_data_frame(lapply(describe_over_500_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_500_hands) <- colnames(describe_over_500_hands)
 rownames(df_describe_500_hands) <- rownames(describe_over_500_hands)
 kable(df_describe_500_hands,caption = "Figure 6 - Over 500")
 
describe_over_1000_hands <- describe(over_1000_hands)
describe_over_1000_hands<- describe_over_1000_hands[predictors,]
df_describe_1000_hands <- as_data_frame(lapply(describe_over_1000_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_1000_hands) <- colnames(describe_over_1000_hands)
 rownames(df_describe_1000_hands) <- rownames(describe_over_1000_hands)
 kable(df_describe_1000_hands,caption = "Figure 7 - Over 1000")
 
describe_over_2500_hands <- describe(over_2500_hands)
describe_over_2500_hands<- describe_over_2500_hands[predictors,]
df_describe_2500_hands <- as_data_frame(lapply(describe_over_2500_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_2500_hands) <- colnames(describe_over_2500_hands)
 rownames(df_describe_2500_hands) <- rownames(describe_over_2500_hands)
 kable(df_describe_2500_hands,caption = "Figure 8 - Over 2500")
 
```
 
 
 
## Run some normality qq plots 
 
```{r}

par(mfrow=c(2, 3)) 
 mapply(qqnorm,over_2500_hands[,predictors],main=colnames(over_50_hands[,predictors]),xlab="Figure 9 -over50 hands") 
 
 par(mfrow=c(2, 3)) 
 mapply(qqnorm,over_100_hands[,predictors],main=colnames(over_100_hands[,predictors]),xlab="Figure 10 - Over100 hands") 
 
 
 par(mfrow=c(2, 3)) 
 mapply(qqnorm,over_500_hands[,predictors],main=colnames(over_2500_hands[,predictors]),xlab="Figure 11 - Over500 hands") 
 
 par(mfrow=c(2, 3)) 
 mapply(qqnorm,over_500_hands[,predictors],main=colnames(over_1000_hands[,predictors]),xlab="Figure 12 - Over1000 hands") 
 
 par(mfrow=c(2, 3)) 
 mapply(qqnorm,over_2500_hands[,predictors],main=colnames(over_2500_hands[,predictors]),xlab="Figure 13 - Over2500 hands") 
 
 


 
#fivenum
 # Describe function, filter for numeric columns,round, rename buit df 
# describe_table <- describe(over_50_hands)
# describe_table <- describe_table[-1,]
# describe_table_2 <- as_data_frame(lapply(describe_table, function(x){       
#                         if(is.numeric(x)) round(x, 2) else x}))
# colnames(describe_table_2) <- colnames(describe_table)
# rownames(describe_table_2) <- rownames(describe_table)
# kable(describe_table_2)
```

### What do these summary statistics mean
+ While i ran descriptive statistics over the entire dataset, the main area of concern is the dependent variable we want to predict, that variable is BB/100
    +  We can also refer to this as the "winrate"
+ Our qqplots of winrate are not very comforting in any of the dataframes.  There appears to be many samples that fall outside  2,3,4 sd from our mean
+  Our histograms also seem to have large tails and don't appear normal
+ With this in mind and with this being a elementary level analysis, i will proceed and attempt to run some linear models 


## Linear models
+ Each model is run
    + Residual plots are graphed(although largely ignored until model is tuned)
    + Summary and Anova results are displayed

### Attempt 1
+ Filter for over 2500 hands
    + This dataframe will consist of players who play rather often, the term for this in poker is "regs"
+ I will create one categorical input known as vpip-pfr.
    + If you refer to the [Data 607 Final](https://rpubs.com/justin_herman_42/385739), I ran some summary staistics on groupings of this stat in the section "do stats really matter" 
    + Below we run code to create a wide_gap and narrow_gap vpip-pfr column
    
```{r}
over_2500_hands<- all_players_finished_db %>% 
    filter(.,total_hands>2500) %>% 
    select(.,c(predictors))
##Create numeric column
over_2500_hands <- over_2500_hands %>% 
    mutate(.,vpip_pfr=vpip-pfr)
## Save this vector for use later
numerical_vpip_pfr <- over_2500_hands$vpip_pfr
## create categorical factor column
over_2500_hands$vpip_pfr[over_2500_hands$vpip_pfr<15.001] <- 1    
over_2500_hands$vpip_pfr[over_2500_hands$vpip_pfr>15.001] <- 0  
my_vector <- str_replace(as.character(over_2500_hands$vpip_pfr),'0', "wide_gap")
my_vector <- str_replace(my_vector,'1', "narrow_gap")
over_2500_hands$vpip_pfr <-as_factor(my_vector) 

## display new df summary stats
summary(over_2500_hands)
```

#### Create first LM model
+ VPIP and PFR may violate indepence between variables assumption as they likely have influence our new vpip_pfr category 
    + We will proceed anyway
+ Target=BB/100(winrate)
+ Input variables- categorical-vpip_pfr, numerical-WWSF,VPIP,PFR,THREE_BET 

```{r}

  y <- over_2500_hands$bb_per_100
 # y <- y-min(y)+1

vpip_pfr <- over_2500_hands$vpip_pfr
WWSF <- over_2500_hands$wwsf
VPIP <- over_2500_hands$vpip
PFR <- over_2500_hands$pfr
THREE_BET <- over_2500_hands$threebet
fit_1 <- lm(y~vpip_pfr+VPIP+THREE_BET+WWSF+PFR)

layout(matrix(c(1,2,3,4),2,2)) 
plot(fit_1)
summary(fit_1)
anova(fit_1)
```

#### Summary of fit_1
+ Narrow gap is worth 2.8 bb( it's p vlaue appears to show it's not signficant)
+ WWSF also appears to not reach significance
    + lets remove WWSF and proceed from there

### Fit_2

+ Removes WWSF
    
```{r}
fit_2 <- lm(y~vpip_pfr+VPIP+THREE_BET+PFR)

layout(matrix(c(1,2,3,4),2,2)) 
plot(fit_2)
summary(fit_2)
anova(fit_2)
```

#### Summary of Fit 2
 + Our model still shows that our categorical data is likely sharing colinearity with vpip and pfr, which makes sense.
    + lets look at the correlations of the inputs 
    + to do so with vpip_pfr we need to use the numeric column we originally created for vpip-pfr

#### Correlation Plot
```{r}
## add vpip-pfr numerical vector
corr_plot_db <- as_data_frame(cbind(over_2500_hands,numerical_vpip_pfr))
##plot correlations
library(corrplot)
corrplot(cor(corr_plot_db[,-6]))
```
 
 
#### Summary of Correlation Plot
 + As i expected numerical vpip_pfr heavily correlates with vpip and pfr, it also laregely negatively correlated with our win rate statistic(bb_per_100)
 + I want to keep the categorical data in there so I will attempt to take out the vpip( has the highest correlation with vpip_pfr)
 
### Fit_3
 
```{r}
fit_3 <- lm(y~vpip_pfr+THREE_BET+PFR)

layout(matrix(c(1,2,3,4),2,2)) 
plot(fit_3)
my_fit <- summary(fit_3)
anova(fit_3)
```
 
#### Summary of Fit 3

+ These results are interesting and I believe they are getting much closer to where we need to be
+ Just for refresher, below are our summary statistics on this database

```{r,echo=FALSE}
describe_over_2500_hands <- describe(over_2500_hands)
describe_over_2500_hands<- describe_over_2500_hands[predictors,]
df_describe_2500_hands <- as_data_frame(lapply(describe_over_2500_hands, function(x){       
                         if(is.numeric(x)) round(x, 2) else x}))
 colnames(df_describe_2500_hands) <- colnames(describe_over_2500_hands)
 rownames(df_describe_2500_hands) <- rownames(describe_over_2500_hands)
 kable(df_describe_2500_hands,caption = "Figure 8 - Over 2500")
```



+ bb/100 it appears the mean is -12 and median is around -8
+ Our intercept in the first model was at 14, its now starting at -15.  This seems to fit the data better 
    + Our categorical grouping of narrow_gap, is now worth 24.38 bb as well
+ Most of our variance is also being explained by our categorical data, although our overall adjusted r^2 does seem worse than it was in the first model
+ lets eyeball this model to my winrate
```{r}
my_stats <- all_players_finished_db %>% 
    filter(playername=="RileyFreeman") %>% 
    select(.,predictors)


for_comparison <- fit_3$coefficients[1]+fit_3$coefficients[2]+my_stats$pfr*(fit_3$coefficients[4])+my_stats$threebet*(fit_3$coefficients[3])      

paste("my actual win rate is", my_stats$bb_per_100,"model predicts ",for_comparison)


```
+ I know a problem with the model is that the relationship of 3 bet can't really be summed up in a linear way, as there are inflection points.  High 3 bets and low 3 bets are bad, I will attempt to square the threebet input to see if the model works better

### Fit_4

+ Square threebet input

```{r,echo=FALSE}
THREE_BET_2 <- THREE_BET**2
fit_4 <- lm(y~vpip_pfr+THREE_BET_2+PFR)

layout(matrix(c(1,2,3,4),2,2)) 
plot(fit_4)
summary(fit_4)
anova(fit_4)


for_comparison <- fit_4$coefficients[1]+fit_4$coefficients[2]+my_stats$pfr*(fit_4$coefficients[4])+my_stats$threebet*(fit_4$coefficients[3])      

paste("my actual win rate is", my_stats$bb_per_100,"model predicts ",for_comparison)
```

+ This model is starting to look better, let me now try to square pfr as well

### Fit 5 
+  Square the pfr as well as threebet

```{r,echo=FALSE}
THREE_BET_2 <- THREE_BET**2
PFR_2 <- PFR**2
fit_5 <- lm(y~vpip_pfr+THREE_BET_2+PFR_2)

layout(matrix(c(1,2,3,4),2,2)) 
plot(fit_5)
summary(fit_5)
anova(fit_5)


for_comparison <- fit_5$coefficients[1]+fit_5$coefficients[2]+my_stats$pfr*(fit_5$coefficients[4])+my_stats$threebet*(fit_5$coefficients[3])      

paste("my actual win rate is", my_stats$bb_per_100,"model predicts ",for_comparison)

```

+ Perhaps this is due to overfitting, but this looks pretty close.  Lets try and run a test train split and see what happens

```{r}
##Create test/train
set.seed(10)
train.idx <- sample(nrow(over_2500_hands),.7*nrow(over_2500_hands),replace = FALSE)
test.idx <- (1:nrow(over_2500_hands))[-train.idx]


## Extract target vector and rest of DF for LM
lm_target <-over_2500_hands[,"bb_per_100"] 
lm_inputs <- over_2500_hands[,c('pfr','threebet',"vpip_pfr")]

train_df <-  over_2500_hands[train.idx,c('pfr','threebet',"vpip_pfr","bb_per_100")]
test_df <- over_2500_hands[test.idx,c('pfr','threebet',"vpip_pfr","bb_per_100")]

THREE_BET_2 <- THREE_BET**2
PFR_2 <- PFR**2

fit_6 <- lm(bb_per_100~vpip_pfr+(threebet**2)+(pfr**2),data=train_df)
fit_6 <- predict(fit_6,test_df)

actual <- over_2500_hands[test.idx,c("bb_per_100")]
error=actual-fit_6
paste("my RMSE is",sqrt(mean(error^2)))
```

#### Summary fit 5
+ Our rmse results aren't that great
    + This is because it looks like our categorical data is doing all the heavy lifting 
    + Therefore our model is evaluating players into essentially two different stratas, and our other dependent variables aren't really doing much
    
    

















##terms to describe - 
+ street- preflop,flop,turn,river



take hands divide by 100 thats our smaples  