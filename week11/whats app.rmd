---
title: "R Notebook"
output: html_notebook
---

```{r}
rm(list=ls())
library(ggplot2)
library(lubridate)
library(Scale)
library(reshape2)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(stringr)
library(syuzhet) 
library(dplyr ) 
library(tidyverse)
library(rlang)
```



```{r}
```



#get the data from whatsapp chat 
```{r}

text <- readLines("_chat.txt")
trans <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
#let us create the corpus
docs <- Corpus(VectorSource(text))

#clean our chat data
trans <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, trans, "/")
docs <- tm_map(docs, trans, "@")
docs <- tm_map(docs, trans, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("friendName"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
```


```{r}


library(tidytext)
#create the document term matrix



dtm <- TermDocumentMatrix(docs)
data<- tidy(dtm)
#str(data)
mat <- removeSparseTerms(dtm, sparse = 0.2)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing=TRUE)
data <- data.frame(word = names(v),freq=v)
head(data, 10)
set.seed(1056)
wordcloud(words = data$word, freq = data$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
Sentiment <- get_nrc_sentiment(text)
head(Sentiment)
text_2 <- cbind(text,Sentiment)

TotalSentiment <- data.frame(colSums(text_2[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment), TotalSentiment)
rownames(TotalSentiment) <- NULL

ggplot(data = TotalSentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")






data_2<- tidy(mat)
#s.df <- as.matrix(mat)
word_freqs = sort(rowSums(s.df), decreasing=TRUE) #now we get the word orders in decreasing order
head(word_freqs,10)


str(data)


ap_sentiments <- data %>%
  inner_join(get_sentiments("bing"), by = c(term = "word"))
library(ggplot2)

ap_sentiments %>%
  count(sentiment, term, wt = count) %>%
  ungroup() %>%
  filter(n >= 150) %>%
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(term = reorder(term, n)) %>%
  ggplot(aes(term, n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Contribution to sentiment")+
    coord_flip()



v <- sort(rowSums(mat),decreasing=TRUE)

#Data frame
data <- data.frame(word = names(v),freq=v)
head(data, 10)


#generate the wordcloud
set.seed(1056)
wordcloud(words = data$term, freq = data$count, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))

#fetch sentiment words from texts
Sentiment <- get_nrc_sentiment(texts)
head(Sentiment)
text <- cbind(texts,Sentiment)

#count the sentiment words by category
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment), TotalSentiment)
rownames(TotalSentiment) <- NULL

#total sentiment score of all texts
ggplot(data = TotalSentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")



head(chat)



```



```{r}

#[^1-9]+
 library(stringr)
chat <- read.csv("_chat.csv",
                 header = FALSE, sep = ",",
                 na.strings="", stringsAsFactors = FALSE)



chat_33 <- as_data_frame(lapply(chat, gsub, pattern='\\[|\\]', replacement=''))


chat_33<- cbind(chat_33, matrix(nrow = nrow(chat_33), ncol = 5))


for(row in grep("^\\D", chat_33[,1])){
      end <- which(is.na(chat_33[row,]))[1] #first column without text in it
      chat_33[row, 6:(5+end)]<- chat_33[row, 1:(end-1)]
      chat_33[row, 1:(end-1)] <- NA
}

chat <- chat_33[-which(apply(chat_33, 1, function(x) all(is.na(x))) == TRUE),]
#Delete rows without ":" in either column 3 nor 4.
#Those are not messages but activities like adding members to a group chat
chat <-chat[grepl(".+:$", chat[,5]) |
                  grepl(".+:$", chat[,4]) | 
                  is.na(chat[,1]), ]

#Filter column 4. Shift everything that's not a surname
#to the first column without content
for(row in which(!grepl(".+:$", chat[,5]))){
      end <- which(is.na(chat[row,]))[1] #first column without chat content
      chat[row,end]<- chat[row,5]
      chat[row,5] <- NA
}

## Step above takes while so lets make experimental df from here
exp_chat <- chat

for(row in which(is.na(exp_chat[,1]))){
      exp_chat[row,1:5] <- exp_chat[(row-1), 1:5]
}


my_vals <- unique(exp_chat$V3)
my_vals <- my_vals[3:22]

exp_chat$V3 <-lapply(exp_chat$V3, function(x) replace(x,x %in% my_vals, "PM") )
#Merge columns 1 and 2 (date and time) to simplify things
exp_chat[,1] <- paste(exp_chat[,1], exp_chat[,2],exp_chat[,3])

#Delete column 3, contains only "-"
exp_chat <- exp_chat[,-3]
#Remove now redundant second column
exp_chat <- exp_chat[,-2]
#Name the first three columns
colnames(exp_chat)[1:3] <- c("time", "name", "surname")

#Convert the first column into a 'Posixlt' object.
exp_chat$time <- strptime(exp_chat$time, format="%m/%d/%Y, %I:%M:%S %p")


exp_chat$name <- gsub(":$", "", exp_chat$name)
exp_chat$surname <- gsub(":$", "", exp_chat$surname)

save(chat, file = "whatsapp_cleaned.Rdata")
exp_chat$time$hour

```

```{r}
ggplot(exp_chat[exp_chat$time$hour >7 &exp_chat$time$hour <22,], aes(x = time$hour, fill = name)) +
  stat_count(position = "dodge", show.legend = TRUE) +
  ggtitle("Journocode conversations per hour") +
  ylab("# of messages") + xlab("hours of day") +
  theme(plot.title = element_text(face = "bold"))



group_chat <- exp_chat
group_chat$time <- as.POSIXct(group_chat$time)
group_chat <- as_data_frame(group_chat)


ggplot(group_chat[group_chat$time$hour >7 &group_chat$time$hour <22,], aes(x = time$hour, fill = name)) +
  stat_count(position = "dodge", show.legend = TRUE) +
  ggtitle("Journocode conversations per hour") +
  ylab("# of messages") + xlab("hours of day") +
  theme(plot.title = element_text(face = "bold"))



```

